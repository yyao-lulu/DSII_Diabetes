---
title: "Data Science 2 Final Project"
author: "Yangwei Yan (yy2828), Yunqiu Yao (yy2827), Boxuan Li (bl2689)"
date: "4/18/2018"
output: 
  html_document:
    code_folding: hide
---

In real life, it is very important to know if a patient will be readmitted in some hospital due to some particular diseases. It is not only because readmission indicates that the patient needs to suffer more from the disease, also a potential reminder that the treatment used previously to treat the patient is not effective enough for the hospital. Generally, readmission should be avoided, which is the major motivation for this study. In this case, a dataset about the readmission status of patients with diabetes extracted from the hospital records, including information on the patient's demographic characteristics, the diagnosis and treatment, is analyzed to explore the impact of those features on the incidence of readmission in the population. This report includes the data description, explanatory study and supervised analysis, which serve to provide sense of the data and relationship among variables in whole.  The result shows that there is assication between serveral covatiates and the readmission occurrence, e.g., (!!!!!!!!!!!!!!!!!). 

```{r R set-up, include=FALSE}
knitr::opts_chunk$set(
  collapse = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.width = 8,
  fig.asp = 1,
  out.width = "90%"
)

library(MASS)
library(tidyverse)
library(janitor)

theme_set(theme_bw())
theme_update(legend.position = "bottom")
```

```{r dataset cleaning and manipulation}
diabetes <- read_csv('./data/diabetic_data.csv') %>%
  clean_names()

# missing value proportion
diabetes[diabetes=="?"] = NA
sapply(diabetes,function(x) sum(is.na(x))/dim(diabetes)[1]) %>% .[.!=0]

# Therefore, we consider to omit those variables with large number of missing values, i.e., 'weight', 'payer code' and 'medical specialty'. We further omit NA values in other variables.
diabetes <- diabetes %>%
  select(., everything(), -weight, -payer_code, -medical_specialty) %>%
  na.omit() %>%
  arrange(patient_nbr) %>% 
  group_by(patient_nbr) %>% 
  filter(row_number(encounter_id)==1,
         !(discharge_disposition_id %in% c(11,13,14,19:21))) %>% 
# Classify the readmitted status into “Yes” if the patient was readmitted in less than 30 days and “No” if the patient was readmitted in more than 30 days or no record of readmission. 
  ungroup() %>% 
  mutate(readmitted=ifelse(readmitted=="<30","Yes","No")) %>% 
  filter(nateglinide %in% c("No","Steady"),
         glyburide_metformin %in% c("No","Steady"),
         gender %in% c("Female","Male"),
         acarbose %in% c("No","Steady"))
# Specify the variable "Diagnosis" as the correspnding diagnosed diseases
diabetes_tidy = diabetes %>% 
  mutate(
    diag_1=ifelse(diag_1>=390 & diag_1 <= 459 | diag_1 == 785, "Circulatory", 
                  ifelse(diag_1>=460 & diag_1 <= 519 | diag_1 == 786, "Respiratory", 
                  ifelse(diag_1>=520 & diag_1 <= 579 | diag_1 == 787, "Digestive",
                  ifelse(substr(diag_1, 1, 3) == 250, "Diabetes", 
                  ifelse(diag_1>=800 & diag_1 <= 999, "Injury",
                  ifelse(diag_1>=710 & diag_1 <= 739, "Musculoskeletal",
                  ifelse(diag_1>=580 & diag_1 <= 629 | diag_1 == 788, "Genitourinary",
                  ifelse(diag_1>=140 & diag_1 <= 239, "Neoplasms", "Other")))))))),
    diag_2=ifelse(diag_2>=390 & diag_2 <= 459 | diag_2 == 785, "Circulatory", 
                  ifelse(diag_2>=460 & diag_2 <= 519 | diag_2 == 786, "Respiratory", 
                  ifelse(diag_2>=520 & diag_2 <= 579 | diag_2 == 787, "Digestive",
                  ifelse(substr(diag_2, 1, 3) == 250, "Diabetes", 
                  ifelse(diag_2>=800 & diag_2 <= 999, "Injury",
                  ifelse(diag_2>=710 & diag_2 <= 739, "Musculoskeletal",
                  ifelse(diag_2>=580 & diag_2 <= 629 | diag_2 == 788, "Genitourinary",
                  ifelse(diag_2>=140 & diag_2 <= 239, "Neoplasms", "Other")))))))),
    diag_3=ifelse(diag_3>=390 & diag_3 <= 459 | diag_3 == 785, "Circulatory", 
                  ifelse(diag_3>=460 & diag_3 <= 519 | diag_3 == 786, "Respiratory", 
                  ifelse(diag_3>=520 & diag_3 <= 579 | diag_3 == 787, "Digestive",
                  ifelse(substr(diag_3, 1, 3) == 250, "Diabetes", 
                  ifelse(diag_3>=800 & diag_3 <= 999, "Injury",
                  ifelse(diag_3>=710 & diag_3 <= 739, "Musculoskeletal",
                  ifelse(diag_3>=580 & diag_3 <= 629 | diag_3 == 788, "Genitourinary",
                  ifelse(diag_3>=140 & diag_3 <= 239, "Neoplasms", "Other")))))))),
  ) 
diabetes_tidy = diabetes_tidy %>% 
  mutate(
    discharge = ifelse(discharge_disposition_id==1, "Home", "Other"),
    admission_source = ifelse(admission_source_id==7, "Emergency",
                  ifelse(admission_source_id %in% 1:3, "Referral", "Other"))
  ) %>% 
  select(-c(encounter_id,patient_nbr,admission_type_id,admission_source_id,discharge_disposition_id,chlorpropamide,acetohexamide,tolbutamide,miglitol,troglitazone,tolazamide,examide,citoglipton,glipizide_metformin,glimepiride_pioglitazone,metformin_rosiglitazone,metformin_pioglitazone)) %>%
  mutate_if(is.character, as.factor)

```

## Data Description
The dataset used in this study was extracted from the Health Facts database (Cerner Corporation, Kansas City, MO), a national data warehouse that collects comprehensive clinical records across hospitals throughout the United States. Information in the dataset was systematically collected from participating institutions electronic medical records. In this case, we focus on the records on "diabetic" encounters. The dataset contains `r nrow(diabetes)` observations and `r ncol(diabetes)` variables before data cleaning. Specifically, it incorporates basic information on each "diabetic" encounter for patients, including several demographic characteristics (i.e., "race", "gender" and "age"), hospital records about diagnosis, medical treatments, and th readmission status for each patient. Most of variables in the dataset are categorical, with two or three categories (e.g., "Yes", "No", "Steady", etc.), indicating whether the patient received some treatments or had some particular features. Information in this dataset can be helpful to evaluate the efficacy of different treatments to reduce the readmission rate of patients due to diabetes. Therefore, the "readmitted" variable is regarded as the main response in the supervised analysis section, which will aim to explore the impact of different treatments to the readmission due to diaebtes. Result of this research is promising to provide some insights in improvement of the diabetes treatment. 

During the data cleaning process, we omitted the variables with too many missing values with the proportion of missing values over 30%, i.e., 'weight', 'payer code' and 'medical specialty'. Subsequently, few missing values left in other variables were omiited as well. Data in the original dataset are considered to be correlated because it contained multiple visits per patients. Thus we used only the first encounter for each patient as the primary admission status. In addtion, we combined "No" and ">30" categories in the "readmitted" variable into ">30" category because it has been verified by research that it is more likely for a patient to readmit after 30 days due to his or her own healthy issues instead of the treatment. Therefore, only readmission within 30 days after discharge was considered to be associated with the treatment in this case, which is why three categories were combined into two indicating readmission related to treatment and readmission irrelevant to treatment respectively. In terms of those numeric variables referring to categorical meanings such as "diag_1", "diag_2", "diag_3" and "discharge", we substituted them with the original implications as factors. Futhermore, multiple variables were found to give extremely separate categories, i.e., the ratio of two categories is less than 0.1%, thus they were also removed and will not be considered in further analyses. Simultaneously, considering the overwhelming data that could cause difficulty in techinics used in supervised analysis, we decided to appropriately reduce the size to 20000 observations randomly.  After the process of data cleaning, the dataset still contains `r nrow(diabetes_tidy)` observations and `r ncol(diabetes_tidy)` variables.

More detailed information can be found in [here](ref:).

## Explanatory Data Analysis
```{r}
# For numeric variables
diabetes_tidy %>% 
  select_if(is.integer) %>% 
  apply(2,summary) %>% 
  pander::pander(caption="For numeric variables")

# For categorical variables
freq.table = function(x,name){
  table = data.frame(x)
  names(table) = c("Value","Count")
  table$Fraction = with(table,Count/sum(Count))
  data.frame(Variable=name,table)
}

fct_diabetes = diabetes_tidy %>%
  select_if(is.factor) %>% 
  lapply(table)

do.call(rbind,lapply(seq_along(fct_diabetes),function(i) freq.table(fct_diabetes[i],names(fct_diabetes[i])))) %>% 
  pander::pander(caption="For categorical variables")

set.seed(100)
rsample = sample(1:nrow(diabetes_tidy), 20000)
diabetes_tidy = diabetes_tidy[rsample, ]
```

The summary and the table presents an basic but comprehensive overview of the dataset, including the class of each variable, the proportion in the population for categorical variables and the related statitics for numeric variables. Based on the table, it can be found that there are 8 continuous and 24 categorical variables after data cleaning. Most patients are caucasian. Remarkably, older people seem to have higher risk for diabetes since the age of patients mostly falls around 70. The mean number of medications prescribed for those patients is about 16, among which insulin is still the major treatment medication since over 50% patients take insulin while the proportion of patients who take other medication is so small. Concerning the response "readmitted", only 10% of all patients studied in this case readmit within 30 days after previous discharge. Even though it is a minor fraction, it is still essential to study how to improve the treatment to avoid readmission.   

## Supervised Analysis

Classification techniques including logistic regression, k-nearest neighbor classifiers, tree-based methods and support vector machines were applied to predict whether a patient would be readmitted in 30 days. By comparing the performance of different techniques, we explored the association between readmission and potential predictors, and compared the prediction accuracy of each technique. 

```{r training set}
# create test set
set.seed(1)
nrow_train = sample(1:nrow(diabetes_tidy), 10000)
```

#### Logistic Model

#### K-nearest neighbor (KNN) classifiers
K-nearest neighbor (KNN) classifiers is one of the model-free classification methods. KNN requires no assumption on the distrbution that generate the data. Thus we applied KNN in our dataset with large amounts of predictors. Since KNN measures the nearest distance between training points and the point $x_0$ to predict, it is impossible to evaluate the distance if the predictor $x_i$ is categorical. For example, it is not rationale to measure the distance between $x_0$ and "female" or $x_0$ and "male". Therefore, we only included numerical predictors to construct the KNN model.

```{r KNN}
# training and test set for knn
readmit = diabetes_tidy[nrow_train,]$readmitted
train = as.data.frame(diabetes_tidy[nrow_train, c(4:10, 14)])
test = diabetes_tidy[-nrow_train, c(4:10, 14)]

# perform KNN
set.seed(1)
library(class)
fit_knn = knn(train, test, cl = readmit, k = 10)
library(caret)
confusionMatrix(fit_knn, diabetes_tidy[-nrow_train,]$readmitted)
```

#### Classification Tree
We fitted a classification tree to the training data and used cross-validation on the training set to determine the optimal tree size by chosing the optimal parameter cp.
```{r classification tree}
set.seed(1)
fit_tree = train(diabetes_tidy[-30], diabetes_tidy$readmitted, 
                   method = "rpart",
                   trControl = trainControl(method = "cv", number = 10))
plot(fit_tree)
pred_tree = predict(fit_tree, newdata = diabetes_tidy[-nrow_train,])
confusionMatrix(pred_tree, diabetes_tidy[-nrow_train,]$readmitted)
```

#### Random Forest

Random forest technique was also used in this case. This method can not only predict the class of each observation in the test set, also measure the importance of variables during the fitting process. The number of variables randomly sampled as candidates at each split in this study was selected as the squre root of number of covariates used to fit the model, i.e., $\sqrt{32-1}\approx6$.

```{r randomforest}
set.seed(1)
library(randomForest)
library(caret)

diabetes_rf <- mutate(diabetes_tidy, readmitted = ifelse(readmitted =='Yes', 1,0)) %>%
  ungroup()

fit_rf = randomForest(readmitted~., data = diabetes_rf, subset = nrow_train, mtry = 6, importance = TRUE)
importance(fit_rf)
pred_rf_prob = predict(fit_rf, newdata=diabetes_tidy[-nrow_train,],type="response")
pred_rf = rep("No",length(pred_rf_prob))
pred_rf[pred_rf_prob>=0.3] = "Yes"
pred_rf = as.factor(pred_rf)
confusionMatrix(pred_rf, diabetes_tidy[-nrow_train,]$readmitted)
```

The plot of "%IncMSE" and "IncNodePurity" presents the impact of each variable on the change of MSE and node purity in each split during the model fitting. %IncMSE is the most robust and informative measure. It is the increase in mse of predictions(estimated with out-of-bag-CV) as a result of variable j being permuted(values randomly shuffled). And the IncNodePurity relates to the loss function which by best splits are chosen. The larger the two values are, the more important the variable is. Hence, both plots indicate that several variables, e.g., "num_medication", "time_in_hospital", "number_lab_procedures",etc., are the most important to accurately predict the response "readmitted". 

After predicting the response in test set, we compared the predicted ones with the true reponse and made the confusion matrix. The test error rate is therefore $(1-0.9014)*100%=9.99%$.


#### Support Vector Machines
```{r svm}
library(e1071)
library(caret)

# model construction
svm.model = svm(readmitted~.,data=diabetes_tidy[nrow_train,],type="C-classification",cost=10,gamma=0.01)

# training error
# svm.pred = predict(svm.model,newdata=diabetes_tidy[-nrow_test,])
# confusionMatrix(svm.pred,diabetes_tidy[nrow_sample,]$readmitted)

# test error
svm.pred.test = predict(svm.model,newdata=diabetes_tidy[-nrow_train,])

confusionMatrix(svm.pred.test,diabetes_tidy[-nrow_train,]$readmitted)

```

#### Logistic Regression
```{r logistic}
logit.fit = glm(readmitted~.,data=diabetes_tidy,subset=nrow_train,family="binomial")
# contrasts(diabetes_tidy$readmitted)
logit.pred.prob = predict(logit.fit,newdata=diabetes_tidy[-nrow_train,],type="response")
logit.pred = rep("No",length(logit.pred.prob))
logit.pred[logit.pred.prob>=0.3] = "Yes"
confusionMatrix(logit.pred,diabetes_tidy[-nrow_train,]$readmitted)
```

