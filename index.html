<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Yangwei Yan (yy2828), Yunqiu Yao (yy2827), Boxuan Li (bl2689)" />


<title>Data Science II Final Project</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="mailto:&lt;you@youremail.com&gt;">
    <span class="fa fa-envelope fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="http://github.com/&lt;YOUR_GH_NAME&gt;/">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Data Science II Final Project</h1>
<h4 class="author"><em>Yangwei Yan (yy2828), Yunqiu Yao (yy2827), Boxuan Li (bl2689)</em></h4>
<h4 class="date"><em>4/18/2018</em></h4>

</div>


<p>In real life, it is very important to know if a patient will be readmitted in some hospital due to some particular diseases. It is not only because readmission indicates that the patient needs to suffer more from the disease, also a potential reminder that the treatment used previously to treat the patient is not effective enough for the hospital. Generally, readmission should be avoided, which is the major motivation for this study. In this case, a dataset about the readmission status of patients with diabetes extracted from the hospital records, including information on the patient’s demographic characteristics, the diagnosis and treatment, is analyzed to explore the impact of those features on the incidence of readmission in the population. This report includes the data description, explanatory study and supervised analysis, which serve to provide sense of the data and relationship among variables in whole. The result shows that there is assication between serveral covatiates and the readmission occurrence, e.g., (!!!!!!!!!!!!!!!!!).</p>
<pre class="r"><code>diabetes &lt;- read_csv(&#39;./data/diabetic_data.csv&#39;) %&gt;%
  clean_names()

# missing value proportion
diabetes[diabetes==&quot;?&quot;] = NA
sapply(diabetes,function(x) sum(is.na(x))/dim(diabetes)[1]) %&gt;% .[.!=0]</code></pre>
<pre><code>##              race            weight        payer_code medical_specialty 
##      0.0223355541      0.9685847926      0.3955741603      0.4908220820 
##            diag_1            diag_2            diag_3 
##      0.0002063558      0.0035178743      0.0139830592</code></pre>
<pre class="r"><code># Therefore, we consider to omit those variables with large number of missing values, i.e., &#39;weight&#39;, &#39;payer code&#39; and &#39;medical specialty&#39;. We further omit NA values in other variables.
diabetes &lt;- diabetes %&gt;%
  select(., everything(), -weight, -payer_code, -medical_specialty) %&gt;%
  na.omit() %&gt;%
  arrange(patient_nbr) %&gt;% 
  group_by(patient_nbr) %&gt;% 
  filter(row_number(encounter_id)==1,
         !(discharge_disposition_id %in% c(11,13,14,19:21))) %&gt;% 
# Classify the readmitted status into “Yes” if the patient was readmitted in less than 30 days and “No” if the patient was readmitted in more than 30 days or no record of readmission. 
  ungroup() %&gt;% 
  mutate(readmitted=ifelse(readmitted==&quot;&lt;30&quot;,&quot;Yes&quot;,&quot;No&quot;)) %&gt;% 
  filter(nateglinide %in% c(&quot;No&quot;,&quot;Steady&quot;),
         glyburide_metformin %in% c(&quot;No&quot;,&quot;Steady&quot;),
         gender %in% c(&quot;Female&quot;,&quot;Male&quot;),
         acarbose %in% c(&quot;No&quot;,&quot;Steady&quot;))
# Specify the variable &quot;Diagnosis&quot; as the correspnding diagnosed diseases
diabetes_tidy = diabetes %&gt;% 
  mutate(
    diag_1=ifelse(diag_1&gt;=390 &amp; diag_1 &lt;= 459 | diag_1 == 785, &quot;Circulatory&quot;, 
                  ifelse(diag_1&gt;=460 &amp; diag_1 &lt;= 519 | diag_1 == 786, &quot;Respiratory&quot;, 
                  ifelse(diag_1&gt;=520 &amp; diag_1 &lt;= 579 | diag_1 == 787, &quot;Digestive&quot;,
                  ifelse(substr(diag_1, 1, 3) == 250, &quot;Diabetes&quot;, 
                  ifelse(diag_1&gt;=800 &amp; diag_1 &lt;= 999, &quot;Injury&quot;,
                  ifelse(diag_1&gt;=710 &amp; diag_1 &lt;= 739, &quot;Musculoskeletal&quot;,
                  ifelse(diag_1&gt;=580 &amp; diag_1 &lt;= 629 | diag_1 == 788, &quot;Genitourinary&quot;,
                  ifelse(diag_1&gt;=140 &amp; diag_1 &lt;= 239, &quot;Neoplasms&quot;, &quot;Other&quot;)))))))),
    diag_2=ifelse(diag_2&gt;=390 &amp; diag_2 &lt;= 459 | diag_2 == 785, &quot;Circulatory&quot;, 
                  ifelse(diag_2&gt;=460 &amp; diag_2 &lt;= 519 | diag_2 == 786, &quot;Respiratory&quot;, 
                  ifelse(diag_2&gt;=520 &amp; diag_2 &lt;= 579 | diag_2 == 787, &quot;Digestive&quot;,
                  ifelse(substr(diag_2, 1, 3) == 250, &quot;Diabetes&quot;, 
                  ifelse(diag_2&gt;=800 &amp; diag_2 &lt;= 999, &quot;Injury&quot;,
                  ifelse(diag_2&gt;=710 &amp; diag_2 &lt;= 739, &quot;Musculoskeletal&quot;,
                  ifelse(diag_2&gt;=580 &amp; diag_2 &lt;= 629 | diag_2 == 788, &quot;Genitourinary&quot;,
                  ifelse(diag_2&gt;=140 &amp; diag_2 &lt;= 239, &quot;Neoplasms&quot;, &quot;Other&quot;)))))))),
    diag_3=ifelse(diag_3&gt;=390 &amp; diag_3 &lt;= 459 | diag_3 == 785, &quot;Circulatory&quot;, 
                  ifelse(diag_3&gt;=460 &amp; diag_3 &lt;= 519 | diag_3 == 786, &quot;Respiratory&quot;, 
                  ifelse(diag_3&gt;=520 &amp; diag_3 &lt;= 579 | diag_3 == 787, &quot;Digestive&quot;,
                  ifelse(substr(diag_3, 1, 3) == 250, &quot;Diabetes&quot;, 
                  ifelse(diag_3&gt;=800 &amp; diag_3 &lt;= 999, &quot;Injury&quot;,
                  ifelse(diag_3&gt;=710 &amp; diag_3 &lt;= 739, &quot;Musculoskeletal&quot;,
                  ifelse(diag_3&gt;=580 &amp; diag_3 &lt;= 629 | diag_3 == 788, &quot;Genitourinary&quot;,
                  ifelse(diag_3&gt;=140 &amp; diag_3 &lt;= 239, &quot;Neoplasms&quot;, &quot;Other&quot;)))))))),
  ) 
diabetes_tidy = diabetes_tidy %&gt;% 
  mutate(
    discharge = ifelse(discharge_disposition_id==1, &quot;Home&quot;, &quot;Other&quot;),
    admission_source = ifelse(admission_source_id==7, &quot;Emergency&quot;,
                  ifelse(admission_source_id %in% 1:3, &quot;Referral&quot;, &quot;Other&quot;))
  ) %&gt;% 
  select(-c(encounter_id,patient_nbr,admission_type_id,admission_source_id,discharge_disposition_id,chlorpropamide,acetohexamide,tolbutamide,miglitol,troglitazone,tolazamide,examide,citoglipton,glipizide_metformin,glimepiride_pioglitazone,metformin_rosiglitazone,metformin_pioglitazone)) %&gt;%
  mutate_if(is.character, as.factor)</code></pre>
<div id="data-description" class="section level2">
<h2>Data Description</h2>
<p>The dataset used in this study was extracted from the Health Facts database (Cerner Corporation, Kansas City, MO), a national data warehouse that collects comprehensive clinical records across hospitals throughout the United States. Information in the dataset was systematically collected from participating institutions electronic medical records. In this case, we focus on the records on “diabetic” encounters. The dataset contains 67069 observations and 47 variables before data cleaning. Specifically, it incorporates basic information on each “diabetic” encounter for patients, including several demographic characteristics (i.e., “race”, “gender” and “age”), hospital records about diagnosis, medical treatments, and th readmission status for each patient. Most of variables in the dataset are categorical, with two or three categories (e.g., “Yes”, “No”, “Steady”, etc.), indicating whether the patient received some treatments or had some particular features. Information in this dataset can be helpful to evaluate the efficacy of different treatments to reduce the readmission rate of patients due to diabetes. Therefore, the “readmitted” variable is regarded as the main response in the supervised analysis section, which will aim to explore the impact of different treatments to the readmission due to diaebtes. Result of this research is promising to provide some insights in improvement of the diabetes treatment.</p>
<p>During the data cleaning process, we omitted the variables with too many missing values with the proportion of missing values over 30%, i.e., ‘weight’, ‘payer code’ and ‘medical specialty’. Subsequently, few missing values left in other variables were omiited as well. Data in the original dataset are considered to be correlated because it contained multiple visits per patients. Thus we used only the first encounter for each patient as the primary admission status. In addtion, we combined “No” and “&gt;30” categories in the “readmitted” variable into “&gt;30” category because it has been verified by research that it is more likely for a patient to readmit after 30 days due to his or her own healthy issues instead of the treatment. Therefore, only readmission within 30 days after discharge was considered to be associated with the treatment in this case, which is why three categories were combined into two indicating readmission related to treatment and readmission irrelevant to treatment respectively. In terms of those numeric variables referring to categorical meanings such as “diag_1”, “diag_2”, “diag_3” and “discharge”, we substituted them with the original implications as factors. Futhermore, multiple variables were found to give extremely separate categories, i.e., the ratio of two categories is less than 0.1%, thus they were also removed and will not be considered in further analyses. Simultaneously, considering the overwhelming data that could cause difficulty in techinics used in supervised analysis, we decided to appropriately reduce the size to 20000 observations randomly. After the process of data cleaning, the dataset still contains 67069 observations and 32 variables.</p>
<p>More detailed information can be found in <a href="ref:">here</a>.</p>
</div>
<div id="explanatory-data-analysis" class="section level2">
<h2>Explanatory Data Analysis</h2>
<pre class="r"><code># summary table for numeric variables
diabetes_tidy %&gt;% 
  select_if(is.integer) %&gt;% 
  apply(2,summary) %&gt;% 
  pander::pander(caption=&quot;For numeric variables&quot;)</code></pre>
<table style="width:97%;">
<caption>For numeric variables (continued below)</caption>
<colgroup>
<col width="19%" />
<col width="26%" />
<col width="29%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">time_in_hospital</th>
<th align="center">num_lab_procedures</th>
<th align="center">num_procedures</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Min.</strong></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>1st Qu.</strong></td>
<td align="center">2</td>
<td align="center">31</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>Median</strong></td>
<td align="center">4</td>
<td align="center">44</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center"><strong>Mean</strong></td>
<td align="center">4.3</td>
<td align="center">42.92</td>
<td align="center">1.44</td>
</tr>
<tr class="odd">
<td align="center"><strong>3rd Qu.</strong></td>
<td align="center">6</td>
<td align="center">57</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center"><strong>Max.</strong></td>
<td align="center">14</td>
<td align="center">132</td>
<td align="center">6</td>
</tr>
</tbody>
</table>
<table>
<caption>Table continues below</caption>
<colgroup>
<col width="19%" />
<col width="25%" />
<col width="27%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">num_medications</th>
<th align="center">number_outpatient</th>
<th align="center">number_emergency</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Min.</strong></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>1st Qu.</strong></td>
<td align="center">10</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>Median</strong></td>
<td align="center">14</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>Mean</strong></td>
<td align="center">15.77</td>
<td align="center">0.2864</td>
<td align="center">0.1069</td>
</tr>
<tr class="odd">
<td align="center"><strong>3rd Qu.</strong></td>
<td align="center">20</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>Max.</strong></td>
<td align="center">81</td>
<td align="center">42</td>
<td align="center">42</td>
</tr>
</tbody>
</table>
<table style="width:72%;">
<colgroup>
<col width="19%" />
<col width="26%" />
<col width="26%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">number_inpatient</th>
<th align="center">number_diagnoses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Min.</strong></td>
<td align="center">0</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center"><strong>1st Qu.</strong></td>
<td align="center">0</td>
<td align="center">6</td>
</tr>
<tr class="odd">
<td align="center"><strong>Median</strong></td>
<td align="center">0</td>
<td align="center">8</td>
</tr>
<tr class="even">
<td align="center"><strong>Mean</strong></td>
<td align="center">0.1834</td>
<td align="center">7.325</td>
</tr>
<tr class="odd">
<td align="center"><strong>3rd Qu.</strong></td>
<td align="center">0</td>
<td align="center">9</td>
</tr>
<tr class="even">
<td align="center"><strong>Max.</strong></td>
<td align="center">12</td>
<td align="center">16</td>
</tr>
</tbody>
</table>
<pre class="r"><code># summary table for categorical variables
freq.table = function(x,name){
  table = data.frame(x)
  names(table) = c(&quot;Value&quot;,&quot;Count&quot;)
  table$Fraction = with(table,Count/sum(Count))
  data.frame(Variable=name,table)
}

fct_diabetes = diabetes_tidy %&gt;%
  select_if(is.factor) %&gt;% 
  lapply(table)

do.call(rbind,lapply(seq_along(fct_diabetes),function(i) freq.table(fct_diabetes[i],names(fct_diabetes[i])))) %&gt;% 
  pander::pander(caption=&quot;For categorical variables&quot;)</code></pre>
<table style="width:82%;">
<caption>For categorical variables</caption>
<colgroup>
<col width="30%" />
<col width="25%" />
<col width="11%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Variable</th>
<th align="center">Value</th>
<th align="center">Count</th>
<th align="center">Fraction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">race</td>
<td align="center">AfricanAmerican</td>
<td align="center">12398</td>
<td align="center">0.1849</td>
</tr>
<tr class="even">
<td align="center">race</td>
<td align="center">Asian</td>
<td align="center">476</td>
<td align="center">0.007097</td>
</tr>
<tr class="odd">
<td align="center">race</td>
<td align="center">Caucasian</td>
<td align="center">51604</td>
<td align="center">0.7694</td>
</tr>
<tr class="even">
<td align="center">race</td>
<td align="center">Hispanic</td>
<td align="center">1459</td>
<td align="center">0.02175</td>
</tr>
<tr class="odd">
<td align="center">race</td>
<td align="center">Other</td>
<td align="center">1132</td>
<td align="center">0.01688</td>
</tr>
<tr class="even">
<td align="center">gender</td>
<td align="center">Female</td>
<td align="center">35777</td>
<td align="center">0.5334</td>
</tr>
<tr class="odd">
<td align="center">gender</td>
<td align="center">Male</td>
<td align="center">31292</td>
<td align="center">0.4666</td>
</tr>
<tr class="even">
<td align="center">age</td>
<td align="center">[0-10)</td>
<td align="center">63</td>
<td align="center">0.0009393</td>
</tr>
<tr class="odd">
<td align="center">age</td>
<td align="center">[10-20)</td>
<td align="center">357</td>
<td align="center">0.005323</td>
</tr>
<tr class="even">
<td align="center">age</td>
<td align="center">[20-30)</td>
<td align="center">1003</td>
<td align="center">0.01495</td>
</tr>
<tr class="odd">
<td align="center">age</td>
<td align="center">[30-40)</td>
<td align="center">2519</td>
<td align="center">0.03756</td>
</tr>
<tr class="even">
<td align="center">age</td>
<td align="center">[40-50)</td>
<td align="center">6477</td>
<td align="center">0.09657</td>
</tr>
<tr class="odd">
<td align="center">age</td>
<td align="center">[50-60)</td>
<td align="center">11878</td>
<td align="center">0.1771</td>
</tr>
<tr class="even">
<td align="center">age</td>
<td align="center">[60-70)</td>
<td align="center">15138</td>
<td align="center">0.2257</td>
</tr>
<tr class="odd">
<td align="center">age</td>
<td align="center">[70-80)</td>
<td align="center">17177</td>
<td align="center">0.2561</td>
</tr>
<tr class="even">
<td align="center">age</td>
<td align="center">[80-90)</td>
<td align="center">10756</td>
<td align="center">0.1604</td>
</tr>
<tr class="odd">
<td align="center">age</td>
<td align="center">[90-100)</td>
<td align="center">1701</td>
<td align="center">0.02536</td>
</tr>
<tr class="even">
<td align="center">diag_1</td>
<td align="center">Circulatory</td>
<td align="center">20773</td>
<td align="center">0.3097</td>
</tr>
<tr class="odd">
<td align="center">diag_1</td>
<td align="center">Diabetes</td>
<td align="center">5129</td>
<td align="center">0.07647</td>
</tr>
<tr class="even">
<td align="center">diag_1</td>
<td align="center">Digestive</td>
<td align="center">6306</td>
<td align="center">0.09402</td>
</tr>
<tr class="odd">
<td align="center">diag_1</td>
<td align="center">Genitourinary</td>
<td align="center">3341</td>
<td align="center">0.04981</td>
</tr>
<tr class="even">
<td align="center">diag_1</td>
<td align="center">Injury</td>
<td align="center">4530</td>
<td align="center">0.06754</td>
</tr>
<tr class="odd">
<td align="center">diag_1</td>
<td align="center">Musculoskeletal</td>
<td align="center">3869</td>
<td align="center">0.05769</td>
</tr>
<tr class="even">
<td align="center">diag_1</td>
<td align="center">Neoplasms</td>
<td align="center">2434</td>
<td align="center">0.03629</td>
</tr>
<tr class="odd">
<td align="center">diag_1</td>
<td align="center">Other</td>
<td align="center">11493</td>
<td align="center">0.1714</td>
</tr>
<tr class="even">
<td align="center">diag_1</td>
<td align="center">Respiratory</td>
<td align="center">9194</td>
<td align="center">0.1371</td>
</tr>
<tr class="odd">
<td align="center">diag_2</td>
<td align="center">Circulatory</td>
<td align="center">21818</td>
<td align="center">0.3253</td>
</tr>
<tr class="even">
<td align="center">diag_2</td>
<td align="center">Diabetes</td>
<td align="center">8899</td>
<td align="center">0.1327</td>
</tr>
<tr class="odd">
<td align="center">diag_2</td>
<td align="center">Digestive</td>
<td align="center">2795</td>
<td align="center">0.04167</td>
</tr>
<tr class="even">
<td align="center">diag_2</td>
<td align="center">Genitourinary</td>
<td align="center">5205</td>
<td align="center">0.07761</td>
</tr>
<tr class="odd">
<td align="center">diag_2</td>
<td align="center">Injury</td>
<td align="center">1766</td>
<td align="center">0.02633</td>
</tr>
<tr class="even">
<td align="center">diag_2</td>
<td align="center">Musculoskeletal</td>
<td align="center">1254</td>
<td align="center">0.0187</td>
</tr>
<tr class="odd">
<td align="center">diag_2</td>
<td align="center">Neoplasms</td>
<td align="center">1561</td>
<td align="center">0.02327</td>
</tr>
<tr class="even">
<td align="center">diag_2</td>
<td align="center">Other</td>
<td align="center">17022</td>
<td align="center">0.2538</td>
</tr>
<tr class="odd">
<td align="center">diag_2</td>
<td align="center">Respiratory</td>
<td align="center">6749</td>
<td align="center">0.1006</td>
</tr>
<tr class="even">
<td align="center">diag_3</td>
<td align="center">Circulatory</td>
<td align="center">20857</td>
<td align="center">0.311</td>
</tr>
<tr class="odd">
<td align="center">diag_3</td>
<td align="center">Diabetes</td>
<td align="center">12202</td>
<td align="center">0.1819</td>
</tr>
<tr class="even">
<td align="center">diag_3</td>
<td align="center">Digestive</td>
<td align="center">2668</td>
<td align="center">0.03978</td>
</tr>
<tr class="odd">
<td align="center">diag_3</td>
<td align="center">Genitourinary</td>
<td align="center">3933</td>
<td align="center">0.05864</td>
</tr>
<tr class="even">
<td align="center">diag_3</td>
<td align="center">Injury</td>
<td align="center">1383</td>
<td align="center">0.02062</td>
</tr>
<tr class="odd">
<td align="center">diag_3</td>
<td align="center">Musculoskeletal</td>
<td align="center">1327</td>
<td align="center">0.01979</td>
</tr>
<tr class="even">
<td align="center">diag_3</td>
<td align="center">Neoplasms</td>
<td align="center">1129</td>
<td align="center">0.01683</td>
</tr>
<tr class="odd">
<td align="center">diag_3</td>
<td align="center">Other</td>
<td align="center">19023</td>
<td align="center">0.2836</td>
</tr>
<tr class="even">
<td align="center">diag_3</td>
<td align="center">Respiratory</td>
<td align="center">4547</td>
<td align="center">0.0678</td>
</tr>
<tr class="odd">
<td align="center">max_glu_serum</td>
<td align="center">&gt;200</td>
<td align="center">906</td>
<td align="center">0.01351</td>
</tr>
<tr class="even">
<td align="center">max_glu_serum</td>
<td align="center">&gt;300</td>
<td align="center">690</td>
<td align="center">0.01029</td>
</tr>
<tr class="odd">
<td align="center">max_glu_serum</td>
<td align="center">None</td>
<td align="center">63818</td>
<td align="center">0.9515</td>
</tr>
<tr class="even">
<td align="center">max_glu_serum</td>
<td align="center">Norm</td>
<td align="center">1655</td>
<td align="center">0.02468</td>
</tr>
<tr class="odd">
<td align="center">a1cresult</td>
<td align="center">&gt;7</td>
<td align="center">2777</td>
<td align="center">0.04141</td>
</tr>
<tr class="even">
<td align="center">a1cresult</td>
<td align="center">&gt;8</td>
<td align="center">5722</td>
<td align="center">0.08532</td>
</tr>
<tr class="odd">
<td align="center">a1cresult</td>
<td align="center">None</td>
<td align="center">54942</td>
<td align="center">0.8192</td>
</tr>
<tr class="even">
<td align="center">a1cresult</td>
<td align="center">Norm</td>
<td align="center">3628</td>
<td align="center">0.05409</td>
</tr>
<tr class="odd">
<td align="center">metformin</td>
<td align="center">Down</td>
<td align="center">414</td>
<td align="center">0.006173</td>
</tr>
<tr class="even">
<td align="center">metformin</td>
<td align="center">No</td>
<td align="center">52790</td>
<td align="center">0.7871</td>
</tr>
<tr class="odd">
<td align="center">metformin</td>
<td align="center">Steady</td>
<td align="center">13079</td>
<td align="center">0.195</td>
</tr>
<tr class="even">
<td align="center">metformin</td>
<td align="center">Up</td>
<td align="center">786</td>
<td align="center">0.01172</td>
</tr>
<tr class="odd">
<td align="center">repaglinide</td>
<td align="center">Down</td>
<td align="center">28</td>
<td align="center">0.0004175</td>
</tr>
<tr class="even">
<td align="center">repaglinide</td>
<td align="center">No</td>
<td align="center">66168</td>
<td align="center">0.9866</td>
</tr>
<tr class="odd">
<td align="center">repaglinide</td>
<td align="center">Steady</td>
<td align="center">805</td>
<td align="center">0.012</td>
</tr>
<tr class="even">
<td align="center">repaglinide</td>
<td align="center">Up</td>
<td align="center">68</td>
<td align="center">0.001014</td>
</tr>
<tr class="odd">
<td align="center">nateglinide</td>
<td align="center">No</td>
<td align="center">66611</td>
<td align="center">0.9932</td>
</tr>
<tr class="even">
<td align="center">nateglinide</td>
<td align="center">Steady</td>
<td align="center">458</td>
<td align="center">0.006829</td>
</tr>
<tr class="odd">
<td align="center">glimepiride</td>
<td align="center">Down</td>
<td align="center">131</td>
<td align="center">0.001953</td>
</tr>
<tr class="even">
<td align="center">glimepiride</td>
<td align="center">No</td>
<td align="center">63532</td>
<td align="center">0.9473</td>
</tr>
<tr class="odd">
<td align="center">glimepiride</td>
<td align="center">Steady</td>
<td align="center">3185</td>
<td align="center">0.04749</td>
</tr>
<tr class="even">
<td align="center">glimepiride</td>
<td align="center">Up</td>
<td align="center">221</td>
<td align="center">0.003295</td>
</tr>
<tr class="odd">
<td align="center">glipizide</td>
<td align="center">Down</td>
<td align="center">357</td>
<td align="center">0.005323</td>
</tr>
<tr class="even">
<td align="center">glipizide</td>
<td align="center">No</td>
<td align="center">58377</td>
<td align="center">0.8704</td>
</tr>
<tr class="odd">
<td align="center">glipizide</td>
<td align="center">Steady</td>
<td align="center">7776</td>
<td align="center">0.1159</td>
</tr>
<tr class="even">
<td align="center">glipizide</td>
<td align="center">Up</td>
<td align="center">559</td>
<td align="center">0.008335</td>
</tr>
<tr class="odd">
<td align="center">glyburide</td>
<td align="center">Down</td>
<td align="center">399</td>
<td align="center">0.005949</td>
</tr>
<tr class="even">
<td align="center">glyburide</td>
<td align="center">No</td>
<td align="center">59611</td>
<td align="center">0.8888</td>
</tr>
<tr class="odd">
<td align="center">glyburide</td>
<td align="center">Steady</td>
<td align="center">6464</td>
<td align="center">0.09638</td>
</tr>
<tr class="even">
<td align="center">glyburide</td>
<td align="center">Up</td>
<td align="center">595</td>
<td align="center">0.008871</td>
</tr>
<tr class="odd">
<td align="center">pioglitazone</td>
<td align="center">Down</td>
<td align="center">79</td>
<td align="center">0.001178</td>
</tr>
<tr class="even">
<td align="center">pioglitazone</td>
<td align="center">No</td>
<td align="center">61998</td>
<td align="center">0.9244</td>
</tr>
<tr class="odd">
<td align="center">pioglitazone</td>
<td align="center">Steady</td>
<td align="center">4823</td>
<td align="center">0.07191</td>
</tr>
<tr class="even">
<td align="center">pioglitazone</td>
<td align="center">Up</td>
<td align="center">169</td>
<td align="center">0.00252</td>
</tr>
<tr class="odd">
<td align="center">rosiglitazone</td>
<td align="center">Down</td>
<td align="center">71</td>
<td align="center">0.001059</td>
</tr>
<tr class="even">
<td align="center">rosiglitazone</td>
<td align="center">No</td>
<td align="center">62570</td>
<td align="center">0.9329</td>
</tr>
<tr class="odd">
<td align="center">rosiglitazone</td>
<td align="center">Steady</td>
<td align="center">4299</td>
<td align="center">0.0641</td>
</tr>
<tr class="even">
<td align="center">rosiglitazone</td>
<td align="center">Up</td>
<td align="center">129</td>
<td align="center">0.001923</td>
</tr>
<tr class="odd">
<td align="center">acarbose</td>
<td align="center">No</td>
<td align="center">66886</td>
<td align="center">0.9973</td>
</tr>
<tr class="even">
<td align="center">acarbose</td>
<td align="center">Steady</td>
<td align="center">183</td>
<td align="center">0.002729</td>
</tr>
<tr class="odd">
<td align="center">insulin</td>
<td align="center">Down</td>
<td align="center">7059</td>
<td align="center">0.1052</td>
</tr>
<tr class="even">
<td align="center">insulin</td>
<td align="center">No</td>
<td align="center">33079</td>
<td align="center">0.4932</td>
</tr>
<tr class="odd">
<td align="center">insulin</td>
<td align="center">Steady</td>
<td align="center">20451</td>
<td align="center">0.3049</td>
</tr>
<tr class="even">
<td align="center">insulin</td>
<td align="center">Up</td>
<td align="center">6480</td>
<td align="center">0.09662</td>
</tr>
<tr class="odd">
<td align="center">glyburide_metformin</td>
<td align="center">No</td>
<td align="center">66611</td>
<td align="center">0.9932</td>
</tr>
<tr class="even">
<td align="center">glyburide_metformin</td>
<td align="center">Steady</td>
<td align="center">458</td>
<td align="center">0.006829</td>
</tr>
<tr class="odd">
<td align="center">change</td>
<td align="center">Ch</td>
<td align="center">30139</td>
<td align="center">0.4494</td>
</tr>
<tr class="even">
<td align="center">change</td>
<td align="center">No</td>
<td align="center">36930</td>
<td align="center">0.5506</td>
</tr>
<tr class="odd">
<td align="center">diabetesmed</td>
<td align="center">No</td>
<td align="center">16119</td>
<td align="center">0.2403</td>
</tr>
<tr class="even">
<td align="center">diabetesmed</td>
<td align="center">Yes</td>
<td align="center">50950</td>
<td align="center">0.7597</td>
</tr>
<tr class="odd">
<td align="center">readmitted</td>
<td align="center">No</td>
<td align="center">60961</td>
<td align="center">0.9089</td>
</tr>
<tr class="even">
<td align="center">readmitted</td>
<td align="center">Yes</td>
<td align="center">6108</td>
<td align="center">0.09107</td>
</tr>
<tr class="odd">
<td align="center">discharge</td>
<td align="center">Home</td>
<td align="center">42204</td>
<td align="center">0.6293</td>
</tr>
<tr class="even">
<td align="center">discharge</td>
<td align="center">Other</td>
<td align="center">24865</td>
<td align="center">0.3707</td>
</tr>
<tr class="odd">
<td align="center">admission_source</td>
<td align="center">Emergency</td>
<td align="center">36103</td>
<td align="center">0.5383</td>
</tr>
<tr class="even">
<td align="center">admission_source</td>
<td align="center">Other</td>
<td align="center">9214</td>
<td align="center">0.1374</td>
</tr>
<tr class="odd">
<td align="center">admission_source</td>
<td align="center">Referral</td>
<td align="center">21752</td>
<td align="center">0.3243</td>
</tr>
</tbody>
</table>
<pre class="r"><code># visualize the associations
# readmitted and age
age = diabetes_tidy %&gt;%
  group_by(age) %&gt;% 
  summarise(count_yes = sum(readmitted == &quot;Yes&quot;),
            count_no = sum(readmitted == &quot;No&quot;),
            proportion = count_yes/(count_yes + count_no))

ggplot(age, aes(age, proportion, group = 1)) + 
  geom_point() +
  geom_line() +
  labs(title = &quot;The Association Between Readmitted Distribution and Age&quot;,
       x = &quot;Age&quot;,
       y = &quot;Readmitted Proportion&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-1-1.png" width="90%" /></p>
<pre class="r"><code># readmitted and primary diagnosis
disease = diabetes_tidy %&gt;%
  group_by(diag_1) %&gt;% 
  summarise(count_yes = sum(readmitted == &quot;Yes&quot;),
            count_no = sum(readmitted == &quot;No&quot;),
            proportion = count_yes/(count_yes + count_no))

overall_prop = sum(disease$count_yes)/(sum(disease$count_yes) + sum(disease$count_no))
ggplot(disease, aes(proportion, diag_1)) +
  geom_point() +
  geom_vline(xintercept = overall_prop, color = &quot;red&quot;) + 
  labs(title = &quot;The Association Between Readmitted Distribution and Diagnosed Disease&quot;,
       x = &quot;Readmitted Proportion&quot;,
       y = &quot;Primary Diagnosis&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-1-2.png" width="90%" /></p>
<pre class="r"><code>set.seed(100)
rsample = sample(1:nrow(diabetes_tidy), 20000)
diabetes_tidy = diabetes_tidy[rsample, ]</code></pre>
<p>The summary and the table presents an basic but comprehensive overview of the dataset, including the class of each variable, the proportion in the population for categorical variables and the related statitics for numeric variables. Based on the table, it can be found that there are 8 continuous and 24 categorical variables after data cleaning. Most patients are caucasian. Remarkably, older people seem to have higher risk for diabetes since the age of patients mostly falls around 70. The mean number of medications prescribed for those patients is about 16, among which insulin is still the major treatment medication since over 50% patients take insulin while the proportion of patients who take other medication is so small. Concerning the response “readmitted”, only 10% of all patients studied in this case readmit within 30 days after previous discharge. Even though it is a minor fraction, it is still essential to study how to improve the treatment to avoid readmission.</p>
</div>
<div id="supervised-analysis" class="section level2">
<h2>Supervised Analysis</h2>
<p>Classification techniques including logistic regression, k-nearest neighbor classifiers, tree-based methods and support vector machines were applied to predict whether a patient would be readmitted in 30 days. By comparing the performance of different techniques, we explored the association between readmission and potential predictors, and compared the prediction accuracy of each technique.</p>
<pre class="r"><code># create test set
set.seed(1)
nrow_train = sample(1:nrow(diabetes_tidy), 10000)</code></pre>
<div id="k-nearest-neighbor-knn-classifiers" class="section level4">
<h4>K-nearest neighbor (KNN) classifiers</h4>
<p>K-nearest neighbor (KNN) classifiers is one of the model-free classification methods. KNN requires no assumption on the distrbution that generate the data. Thus we applied KNN in our dataset with large amounts of predictors. Since KNN measures the nearest distance between training points and the point <span class="math inline">\(x_0\)</span> to predict, it is impossible to evaluate the distance if the predictor <span class="math inline">\(x_i\)</span> is categorical. For example, it is not rationale to measure the distance between <span class="math inline">\(x_0\)</span> and “female” or <span class="math inline">\(x_0\)</span> and “male”. Therefore, we only included numerical predictors to construct the KNN model.</p>
<pre class="r"><code># training and test set for knn
readmit = diabetes_tidy[nrow_train,]$readmitted
train = as.data.frame(diabetes_tidy[nrow_train, c(4:10, 14)])
test = diabetes_tidy[-nrow_train, c(4:10, 14)]

# perform KNN
set.seed(1)
pred_knn_prob = 1-attributes(knn(train, test, prob=TRUE,cl = readmit, k = 10))$prob
pred_knn = knn(train, test, cl = readmit, k = 10)
cm.knn = confusionMatrix(pred_knn, diabetes_tidy[-nrow_train,]$readmitted); cm.knn</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   No  Yes
##        No  9034  958
##        Yes    6    2
##                                           
##                Accuracy : 0.9036          
##                  95% CI : (0.8976, 0.9093)
##     No Information Rate : 0.904           
##     P-Value [Acc &gt; NIR] : 0.5625          
##                                           
##                   Kappa : 0.0025          
##  Mcnemar&#39;s Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.999336        
##             Specificity : 0.002083        
##          Pos Pred Value : 0.904123        
##          Neg Pred Value : 0.250000        
##              Prevalence : 0.904000        
##          Detection Rate : 0.903400        
##    Detection Prevalence : 0.999200        
##       Balanced Accuracy : 0.500710        
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
</div>
<div id="classification-tree" class="section level4">
<h4>Classification Tree</h4>
<p>We fitted a classification tree to the training data and used cross-validation on the training set to determine the optimal tree size by chosing the optimal parameter cp.</p>
<pre class="r"><code>set.seed(1)
train_tree = diabetes_tidy[nrow_train,]
fit_tree = train(train_tree[,-30],
                 train_tree$readmitted,
                 method = &quot;rpart&quot;,
                 trControl = trainControl(method = &quot;cv&quot;, number = 10))
plot(fit_tree)</code></pre>
<p><img src="index_files/figure-html/classification%20tree-1.png" width="90%" /></p>
<pre class="r"><code>pred_tree_prob = predict(fit_tree, newdata = diabetes_tidy[-nrow_train,],type=&quot;prob&quot;)
pred_tree = predict(fit_tree, newdata = diabetes_tidy[-nrow_train,])
cm.tree = confusionMatrix(pred_tree, diabetes_tidy[-nrow_train,]$readmitted); cm.tree</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   No  Yes
##        No  9040  960
##        Yes    0    0
##                                           
##                Accuracy : 0.904           
##                  95% CI : (0.8981, 0.9097)
##     No Information Rate : 0.904           
##     P-Value [Acc &gt; NIR] : 0.5086          
##                                           
##                   Kappa : 0               
##  Mcnemar&#39;s Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 1.000           
##             Specificity : 0.000           
##          Pos Pred Value : 0.904           
##          Neg Pred Value :   NaN           
##              Prevalence : 0.904           
##          Detection Rate : 0.904           
##    Detection Prevalence : 1.000           
##       Balanced Accuracy : 0.500           
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
</div>
<div id="random-forest" class="section level4">
<h4>Random Forest</h4>
<p>Random forest technique was also used in this case. This method can not only predict the class of each observation in the test set, also measure the importance of variables during the fitting process. The number of variables randomly sampled as candidates at each split in this study was selected as the squre root of number of covariates used to fit the model, i.e., <span class="math inline">\(\sqrt{32-1}\approx6\)</span>.</p>
<pre class="r"><code>set.seed(1)
library(randomForest)

diabetes_rf &lt;- mutate(diabetes_tidy, readmitted = ifelse(readmitted ==&#39;Yes&#39;, 1,0)) %&gt;%
  ungroup()

fit_rf = randomForest(readmitted~., data = diabetes_rf, subset = nrow_train, mtry = 6, importance = TRUE)
importance(fit_rf)</code></pre>
<pre><code>##                          %IncMSE IncNodePurity
## race                 1.475128776     16.427177
## gender               1.039556573     12.577898
## age                  5.991703885     47.414386
## time_in_hospital    22.960935635     44.048520
## num_lab_procedures  12.829265029     72.438574
## num_procedures      13.643868683     29.382030
## num_medications     22.925264428     61.410106
## number_outpatient    3.347708995     14.544069
## number_emergency     4.746811979     12.063894
## number_inpatient     8.005659149     20.104052
## diag_1               9.342682732     55.914041
## diag_2               2.648715098     51.872791
## diag_3               2.567812945     51.143330
## number_diagnoses     9.655865182     28.768630
## max_glu_serum        3.460470992      6.465836
## a1cresult            3.140582111     17.633544
## metformin            2.214237873     10.763319
## repaglinide         -0.063450978      3.983521
## nateglinide         -3.237879237      1.137922
## glimepiride         -1.065210815      7.030917
## glipizide            0.543395834     12.359675
## glyburide           -3.054999105     10.188727
## pioglitazone         1.004802009      7.558081
## rosiglitazone        0.485425416      7.095148
## acarbose            -0.006939896      0.041650
## insulin              1.840106476     26.630346
## glyburide_metformin -0.621761241      1.065291
## change               5.398968849      9.959202
## diabetesmed          0.613483585      7.735407
## discharge           16.527660299      9.716665
## admission_source     6.041712161     20.321678</code></pre>
<pre class="r"><code>pred_rf_prob = predict(fit_rf, newdata=diabetes_tidy[-nrow_train,],type=&quot;response&quot;)
pred_rf = rep(&quot;No&quot;,length(pred_rf_prob))
pred_rf[pred_rf_prob&gt;=0.3] = &quot;Yes&quot;
pred_rf = as.factor(pred_rf)
cm.rf = confusionMatrix(pred_rf, diabetes_tidy[-nrow_train,]$readmitted); cm.rf</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   No  Yes
##        No  9002  948
##        Yes   38   12
##                                           
##                Accuracy : 0.9014          
##                  95% CI : (0.8954, 0.9072)
##     No Information Rate : 0.904           
##     P-Value [Acc &gt; NIR] : 0.8161          
##                                           
##                   Kappa : 0.0144          
##  Mcnemar&#39;s Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.9958          
##             Specificity : 0.0125          
##          Pos Pred Value : 0.9047          
##          Neg Pred Value : 0.2400          
##              Prevalence : 0.9040          
##          Detection Rate : 0.9002          
##    Detection Prevalence : 0.9950          
##       Balanced Accuracy : 0.5041          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<p>The plot of “%IncMSE” and “IncNodePurity” presents the impact of each variable on the change of MSE and node purity in each split during the model fitting. %IncMSE is the most robust and informative measure. It is the increase in mse of predictions(estimated with out-of-bag-CV) as a result of variable j being permuted(values randomly shuffled). And the IncNodePurity relates to the loss function which by best splits are chosen. The larger the two values are, the more important the variable is. Hence, both plots indicate that several variables, e.g., “num_medication”, “time_in_hospital”, “number_lab_procedures”,etc., are the most important to accurately predict the response “readmitted”.</p>
<p>After predicting the response in test set, we compared the predicted ones with the true reponse and made the confusion matrix. The test error rate is therefore <span class="math inline">\((1-0.9014)*100%=9.99%\)</span>.</p>
</div>
<div id="support-vector-machines" class="section level4">
<h4>Support Vector Machines</h4>
<pre class="r"><code>library(e1071)

# model construction
svm.model = svm(readmitted~.,data=diabetes_tidy[nrow_train,],probability=TRUE,type=&quot;C-classification&quot;,cost=10,gamma=0.01)

pred_svm_prob = attributes(predict(svm.model,newdata=diabetes_tidy[-nrow_train,],probability=TRUE))$probabilities

pred_svm = predict(svm.model,newdata=diabetes_tidy[-nrow_train,])

cm.svm = confusionMatrix(pred_svm,diabetes_tidy[-nrow_train,]$readmitted); cm.svm</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   No  Yes
##        No  9036  958
##        Yes    4    2
##                                           
##                Accuracy : 0.9038          
##                  95% CI : (0.8979, 0.9095)
##     No Information Rate : 0.904           
##     P-Value [Acc &gt; NIR] : 0.5356          
##                                           
##                   Kappa : 0.003           
##  Mcnemar&#39;s Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.999558        
##             Specificity : 0.002083        
##          Pos Pred Value : 0.904142        
##          Neg Pred Value : 0.333333        
##              Prevalence : 0.904000        
##          Detection Rate : 0.903600        
##    Detection Prevalence : 0.999400        
##       Balanced Accuracy : 0.500820        
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<p>Here we tried to use support vector machine to perform the classification. In order to capture the potential nonlinearities in the support-vector classifiers and to obtain better prediction, we use the radial kernel for svm. The result shows that we have a low overall error rate (9.62%) for the prediction. The sensitivity is extremely high, with a value 99.96%, while the specificity is very low, which is only 0.21%. This means the svm model performs quite well on identifing those who do not need to be readmitted (true negative), but has poor ability on the identification of those who require readmission (true positive).</p>
</div>
<div id="logistic-regression" class="section level4">
<h4>Logistic Regression</h4>
<pre class="r"><code>log.fit = glm(readmitted~.,data=diabetes_tidy,subset=nrow_train,family=&quot;binomial&quot;)
# contrasts(diabetes_tidy$readmitted)
pred.log.prob = predict(log.fit,newdata=diabetes_tidy[-nrow_train,],type=&quot;response&quot;)
pred_log = rep(&quot;No&quot;,length(pred.log.prob))
pred_log[pred.log.prob&gt;=0.3] = &quot;Yes&quot;
cm.log = confusionMatrix(pred_log,diabetes_tidy[-nrow_train,]$readmitted); cm.log</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   No  Yes
##        No  9002  946
##        Yes   38   14
##                                           
##                Accuracy : 0.9016          
##                  95% CI : (0.8956, 0.9074)
##     No Information Rate : 0.904           
##     P-Value [Acc &gt; NIR] : 0.7976          
##                                           
##                   Kappa : 0.018           
##  Mcnemar&#39;s Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.99580         
##             Specificity : 0.01458         
##          Pos Pred Value : 0.90491         
##          Neg Pred Value : 0.26923         
##              Prevalence : 0.90400         
##          Detection Rate : 0.90020         
##    Detection Prevalence : 0.99480         
##       Balanced Accuracy : 0.50519         
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<p>Logistic regression is also a common way to address the classification problems. It can be seen from the table above that the overall error of the logistic model for presiction is very low, at around 10%. But similar to the SVM model, the logistic model also has a high sensitivity but a low specificity. Therefore, the model is also more suitable for the identification of those who are not necessarily to be re-admitted.</p>
<pre class="r"><code># roc curves
library(pROC)
roc.knn = roc(diabetes_tidy[-nrow_train,]$readmitted,pred_knn_prob,levels=c(&quot;No&quot;,&quot;Yes&quot;))
auc.knn = roc.knn$auc
roc.tree = roc(diabetes_tidy[-nrow_train,]$readmitted,pred_tree_prob[,2],levels=c(&quot;No&quot;,&quot;Yes&quot;))
auc.tree = roc.tree$auc
roc.rf = roc(diabetes_tidy[-nrow_train,]$readmitted,pred_rf_prob,levels=c(&quot;No&quot;,&quot;Yes&quot;))
auc.rf = roc.rf$auc
roc.svm = roc(diabetes_tidy[-nrow_train,]$readmitted,pred_svm_prob[,2],levels=c(&quot;No&quot;,&quot;Yes&quot;))
auc.svm = roc.svm$auc
roc.log = roc(diabetes_tidy[-nrow_train,]$readmitted,pred.log.prob,levels=c(&quot;No&quot;,&quot;Yes&quot;))
auc.log = roc.log$auc

# roc plot
plot(roc.knn,legacy.axes=TRUE,col=&quot;red&quot;)
plot(roc.tree,add=TRUE,col=&quot;orange&quot;)
plot(roc.rf,add=TRUE,col=&quot;maroon&quot;)
plot(roc.svm,add=TRUE,col=&quot;yellow&quot;)
plot(roc.log,add=TRUE,col=&quot;brown&quot;)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-2-1.png" width="90%" /></p>
<pre class="r"><code># summary table
method = c(&quot;KNN&quot;,&quot;Classification Tree&quot;,&quot;Random Forest&quot;,&quot;SVM&quot;,&quot;Logistic&quot;)
auc = round(c(auc.knn,auc.tree,auc.rf,auc.svm,auc.log),3)
error = round(1-c(cm.knn$overall[[1]],cm.tree$overall[[1]],cm.rf$overall[[1]],cm.svm$overall[[1]],cm.log$overall[[1]]),5)
sens = round(c(cm.knn$byClass[[1]],cm.tree$byClass[[1]],cm.rf$byClass[[1]],cm.svm$byClass[[1]],cm.log$byClass[[1]]),6)
spec = round(c(cm.knn$byClass[[2]],cm.tree$byClass[[2]],cm.rf$byClass[[2]],cm.svm$byClass[[2]],cm.log$byClass[[2]]),6)
comp = cbind(method,auc,error,sens,spec)
colnames(comp) = c(&quot;Method&quot;,&quot;AUC&quot;,&quot;Error Rate&quot;,&quot;Sensitivity&quot;,&quot;Specificity&quot;)
pander::pander(comp)</code></pre>
<table style="width:99%;">
<colgroup>
<col width="30%" />
<col width="11%" />
<col width="18%" />
<col width="19%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Method</th>
<th align="center">AUC</th>
<th align="center">Error Rate</th>
<th align="center">Sensitivity</th>
<th align="center">Specificity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">KNN</td>
<td align="center">0.532</td>
<td align="center">0.0964</td>
<td align="center">0.999336</td>
<td align="center">0.002083</td>
</tr>
<tr class="even">
<td align="center">Classification Tree</td>
<td align="center">0.5</td>
<td align="center">0.096</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">Random Forest</td>
<td align="center">0.584</td>
<td align="center">0.0986</td>
<td align="center">0.995796</td>
<td align="center">0.0125</td>
</tr>
<tr class="even">
<td align="center">SVM</td>
<td align="center">0.524</td>
<td align="center">0.0962</td>
<td align="center">0.999558</td>
<td align="center">0.002083</td>
</tr>
<tr class="odd">
<td align="center">Logistic</td>
<td align="center">0.62</td>
<td align="center">0.0984</td>
<td align="center">0.995796</td>
<td align="center">0.014583</td>
</tr>
</tbody>
</table>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
